{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08fa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyDHOm12uVK7QEExxl7w8fcQGtHGRH7W0OY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GOOGLE_API_KEY = \"YOUR_GOOGLE API_KEY\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "print(GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6204b43f",
   "metadata": {},
   "source": [
    "Minimal Demo (No Server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366ad4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"podcastTitle\": \"TechForward: NVIDIA's New AI GPUs - A Game Changer?\",\n",
      "  \"episodeTitle\": \"Powering the Next Generation of AI\",\n",
      "  \"segments\": [\n",
      "    {\n",
      "      \"segmentTitle\": \"Introduction: A New Era of AI Acceleration\",\n",
      "      \"script\": [\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"Welcome back to TechForward, the podcast that keeps you up-to-date on the latest breakthroughs in technology. Today, we're diving deep into NVIDIA's recent announcement that's shaking up the AI landscape.\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"They've unveiled a groundbreaking new class of GPUs specifically designed to supercharge AI inference and training.  We're talking about significant improvements in efficiency, memory bandwidth, and support for mixed-precision operations – all leading to faster, more cost-effective AI.\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"In this episode, we'll explore the key features of these new chips, the impact they'll have on various industries, and what this means for developers and businesses alike.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"segmentTitle\": \"Deep Dive: Features, Partnerships, and Industry Impact\",\n",
      "      \"script\": [\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"The standout features of these new NVIDIA GPUs are their exceptional efficiency per watt, drastically improved memory bandwidth, and native support for mixed-precision operations. This translates to faster model fine-tuning, lower latency for applications like multimodal assistants, and significant cost reductions.\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"NVIDIA has also announced key partnerships with major cloud providers and enterprises, ensuring widespread adoption and integration into existing workflows.  We're seeing demos showcasing dramatically faster performance in real-world scenarios.\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"Analysts believe these advancements will propel on-device and edge AI forward, making even smaller AI models incredibly powerful and accessible.  Imagine the possibilities: faster processing for robotics, real-time diagnostics in healthcare, and enhanced responsiveness in media applications.\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"Furthermore, NVIDIA’s commitment to software optimization with CUDA libraries and new developer tooling will streamline deployment and allow for quicker iterations for development teams. This will translate to better utilization of resources and measurable cost savings, particularly for inference at scale.\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"The broader industry implications are equally exciting.  We can expect increased competition, more experimentation with compact AI architectures, and the emergence of entirely new AI applications across diverse sectors.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"segmentTitle\": \"Outro: The Future of AI is Now\",\n",
      "      \"script\": [\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"NVIDIA's new GPUs represent a significant leap forward in AI technology, promising faster, more efficient, and more accessible AI solutions.  The implications for developers, businesses, and the broader industry are vast and profound.\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Host\",\n",
      "          \"line\": \"We'll continue to monitor developments in this space and bring you updates as they happen. Thanks for listening to TechForward. Be sure to subscribe for more insightful discussions on the future of technology.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "source_text = \"NVIDIA unveiled a new class of GPUs aimed at AI inference and training, emphasizing higher efficiency per watt, improved memory bandwidth, and native support for mixed-precision operations. The announcement highlighted partnerships with major cloud providers and enterprises building real-time AI workflows. In demos, the company showed faster model fine-tuning and lower latency for multimodal assistants. Analysts expect these chips to push on-device and edge AI forward, making small models more useful and reducing costs. The roadmap also mentions software optimizations in CUDA libraries and new developer tooling to simplify deployment. For teams, this could mean quicker iterations, better utilization, and measurable savings on inference at scale. The broader industry impact may include stronger competition among vendors, more experimentation with compact architectures, and new use cases in media, robotics, and healthcare where responsiveness matters.\"\n",
    "prompt = f\"Turn this into a podcast script (intro, 2 segments, outro, JSON only):\\n\\n{source_text}\"\n",
    "resp = model.generate_content(prompt)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e2a6a",
   "metadata": {},
   "source": [
    "Timestamp Utility Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "743ecf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 2, 2], [0, 2, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "def estimate_timestamps(texts, wpm=150):\n",
    "    spw = 60.0 / wpm\n",
    "    secs = [ceil(len(t.split()) * spw) for t in texts]\n",
    "    stamps = []\n",
    "    t = 0\n",
    "    for s in secs:\n",
    "        stamps.append(t)\n",
    "        t += s\n",
    "    return secs, stamps\n",
    "\n",
    "texts = [\"intro text ...\", \"segment one text ...\", \"segment two text ...\"]\n",
    "dur, starts = estimate_timestamps(texts, 150)\n",
    "dur, starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1049f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26269df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
